{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "5b0acfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "683f4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read the excel file and get all the sheets\n",
    "# xls = pd.ExcelFile('data.xlsx')\n",
    "# # get the names of all sheets\n",
    "# sheet_names = xls.sheet_names\n",
    "\n",
    "# print(\"Sheet names:\", sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "6048da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "85a4a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop through each sheet\n",
    "# for sheet_name in sheet_names:\n",
    "#     # Read the sheet into a DataFrame\n",
    "#     df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "#     # Add a new column with the sheet name\n",
    "#     df['category'] = sheet_name  # No need to add quotes around the sheet name\n",
    "#     # Concatenate the dataframes\n",
    "#     all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "\n",
    "# all_data = all_data.dropna(how='all', axis=1)  # Drop columns that are completely empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "5304deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add a product_id column at the beginning\n",
    "# all_data.insert(0, 'product_id', range(1, len(all_data) + 1))\n",
    "\n",
    "# all_data = all_data.rename(columns=lambda x: x.strip())  # Remove leading and trailing spaces from column names\n",
    "\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "621c6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # move the 'category' column next to the name column\n",
    "# category_col = all_data.pop('category')\n",
    "# all_data.insert(2, 'category', category_col)\n",
    "\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "ccf5ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the final DataFrame to a new csv file\n",
    "# all_data.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "id": "31e973c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "id": "e14e6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave data where catogory is \"Fruits & Vegetables\"\n",
    "data = data[data['category'] != 'Fruits & Vegetables']\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "id": "470a57e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = data['name']\n",
    "\n",
    "# if any two names have first word same, add them to a group\n",
    "groups = {}\n",
    "for name in all_names:\n",
    "    first_word = name.split()[0]\n",
    "    if first_word not in groups:\n",
    "        groups[first_word] = []\n",
    "    groups[first_word].append(name)\n",
    "\n",
    "# for each key in groups, remove the duplicates from the value list\n",
    "for key, value in groups.items():\n",
    "    groups[key] = list(set(value))\n",
    "\n",
    "# add the groups with only one name to a new dictionary \n",
    "no_groups = {}\n",
    "for key, value in groups.items():\n",
    "    if len(value) == 1:\n",
    "        no_groups[key] = value\n",
    "# remove the groups with only one name from the original dictionary\n",
    "for key in no_groups.keys():\n",
    "    del groups[key]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "id": "88f6181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of elements in no_groups\n",
    "# len(no_groups)\n",
    "# no_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "id": "38b87a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print the groups\n",
    "# for key, value in groups.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "id": "7168553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each key in groups, find the longest matching string in the value list\n",
    "def find_longest_matching_string(strings):\n",
    "    if not strings:\n",
    "        return \"\"\n",
    "    \n",
    "    min_words_in_group = 1000\n",
    "    lss = []\n",
    "    for s in strings:\n",
    "        lss.append(s.split())\n",
    "        min_words_in_group = min(min_words_in_group, len(s.split()))\n",
    "    \n",
    "    max_words_matched = 0\n",
    "    for i in range(min_words_in_group):\n",
    "        words = []\n",
    "        for s in lss:\n",
    "            words.append(s[i])\n",
    "        if len(set(words)) == 1:\n",
    "            max_words_matched += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return \" \".join(lss[0][:max_words_matched])\n",
    "# find the longest matching string in each group\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "id": "a6054ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_matching_strings = {}\n",
    "for key, value in groups.items():\n",
    "    longest_matching_strings[key] = find_longest_matching_string(value)\n",
    "    \n",
    "# print the longest matching strings\n",
    "# for key, value in longest_matching_strings.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "id": "df4fefd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to the data with the brand name\n",
    "data.insert(2, 'brand', \"NANA\")\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "id": "9876a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each key in groups, for each value in value list, find the index of the values in the data and set the brand name to the longest matching string\n",
    "for key, value in groups.items():\n",
    "    for v in value:\n",
    "        indices = data[data['name'] == v].index\n",
    "        for i in indices:\n",
    "            data.at[i, 'brand'] = longest_matching_strings[key]\n",
    "        \n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "6645040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.loc[data['name'].str.contains(\"TilSona\"), 'brand'] = \"TilSona\"\n",
    "data.loc[data['name'].str.contains(\"Nissin\"), 'brand'] = \"Nissin\"\n",
    "data.loc[data['name'].str.contains(\"Puro\"), 'brand'] = \"Puro Healthy\"\n",
    "data.loc[data['name'].str.contains(\"Catch\"), 'brand'] = \"Catch\"\n",
    "data.loc[data['name'].str.contains(\"Japanese Choice\"), 'brand'] = \"Japanese Choice\"\n",
    "data.loc[data['name'].str.contains(\"India Gate\"), 'brand'] = \"India Gate\"\n",
    "data.loc[data['name'].str.contains(\"Dlicia Whip\"), 'brand'] = \"Dlicia\"\n",
    "data.loc[data['name'].str.contains(\"Jivana Jaggery\"), 'brand'] = \"Jivana\"\n",
    "data.loc[data['name'].str.contains(\"Horlicks\"), 'brand'] = \"Horlicks\"\n",
    "data.loc[data['name'].str.contains(\"Sugarlite\"), 'brand'] = \"Sugarlite\"\n",
    "\n",
    "# now remove the rows where brand is \"NANA\"\n",
    "data = data[data['brand'] != \"NANA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "id": "f20fe769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of rows with the same name and same weightInGrams\n",
    "data['name_weight'] = data['name'] + \" \" + data['weightInGms'].astype(str)\n",
    "name_counts = data['name_weight'].value_counts()\n",
    "\n",
    "# print the name counts\n",
    "# for name, count in name_counts.items():\n",
    "#     print(f\"{name}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "id": "10a3a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicates in name_weight and keep the first occurrence\n",
    "data = data.drop_duplicates(subset=['name_weight'], keep='first')\n",
    "\n",
    "# remove the name_weight column\n",
    "data = data.drop(columns=['name_weight'])\n",
    "\n",
    "data['name_weight'] = data['name'] + \" \" + data['weightInGms'].astype(str)\n",
    "name_counts = data['name_weight'].value_counts()\n",
    "\n",
    "# print the name counts\n",
    "# for name, count in name_counts.items():\n",
    "#     print(f\"{name}: {count}\")\n",
    "    \n",
    "data = data.drop(columns=['name_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "id": "38bcc6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data to a new csv file\n",
    "data.to_csv('data_with_brand.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
